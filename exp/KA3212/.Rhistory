options(width = 80) # mejora la visual de la salida
AIC_AR <- vector()
for (p in 1:15){
modelo <- arima(goog_entrenamiento_dif, order = c(p,0,0))
AIC_AR[p] <- modelo$aic
}
AIC_AR
AIC_AR <- data.frame(Órden = 1:15, AIC = AIC_AR)
minAIC_AR <- filter(AIC_AR, AIC == min(AIC))
minAIC_AR
ggplot(AIC_AR, aes(x = Órden, y = AIC)) +
geom_line(color = "purple") +
geom_point(data = minAIC_AR, aes(x = Órden, y = AIC), size = 2, color = "magenta")
AR <- arima(goog_entrenamiento_dif, order = c(4,0,0), method = "ML")
round(summary(AR)$coef, 4)
predAR <- forecast(AR, h = 10)
options(width = 80) # mejora la visual de la salida
accuracy(predAR, goog_prueba_dif)
plotAR <- autoplot(predAR, xlab = "Tiempo", ylab = "Precios diferenciados", size = 1) +
theme_hc() +
theme(plot.title = element_text(size = 10, hjust = 0.5),
axis.title = element_text(size = 10),
axis.text = element_text(size = 10))
plotARzoom <- autoplot(goog_prueba_dif, xlab = "Tiempo", ylab = "Precios diferenciados", size = 1) +
autolayer(predAR, alpha = .5) +
ggtitle("Predicciones vs. valores reales")  +
theme_hc() +
theme(plot.title = element_text(size = 10, hjust = 0.5),
axis.title = element_text(size = 10),
axis.text = element_text(size = 10))
grid.arrange(plotAR, plotARzoom, ncol = 2)
checkresiduals(AR)
data(nottem)
nottem_da <- decompose(nottem, type = "additive")
nottem_dm <- decompose(nottem, type = "multiplicative")
plot.ts(nottem_da$random, col = "cyan", xlab = "Año", ylab = "grados")
plot.ts(nottem_dm$random, col = "cyan", xlab = "Año", ylab = "grados")
checkresiduals(nottem_da)
nottem_entrenamiento <- window(nottem, end = c(1938, 12))
nottem_prueba <- window(nottem, start = c(1939, 1))
lamb <- BoxCox.lambda(nottem)
lamb
nottemBC <- BoxCox(nottem, lambda = lamb)
sto <- autoplot(nottem, color = "royalblue", main =  "Serie de tiempo original", xlab = "", ylab = "") +
theme_hc() +
theme(plot.title = element_text(hjust = 0.5))
stt <- autoplot(nottemBC, color = "purple", main =  "Serie de tiempo transformada", xlab = "", ylab = "") +
theme_hc() +
theme(plot.title = element_text(hjust = 0.5))
grid.arrange(sto, stt, ncol = 1)
PP.test(nottem)
library(tseries)
kpss.test(nottem)
kpss.test(goog_dif)
#calcular componentes:
#d=0 porque no se realizo diferenciacion
#p=
Acf(nottem, lag.max = 50, type = "partial", main = "")
#25
#calcular componentes:
#d=0 porque no se realizo diferenciacion
#p=
Acf(nottem, lag.max = 50, type = "partial", main = "")
#25
options(width = 80) # mejora la visual de la salida
AIC_AR <- vector()
for (p in 1:30){
modelo <- arima(nottem_entrenamiento, order = c(p,0,0))
AIC_AR[p] <- modelo$aic
}
AIC_AR
AIC_AR <- data.frame(Órden = 1:30, AIC = AIC_AR)
minAIC_AR <- filter(AIC_AR, AIC == min(AIC))
minAIC_AR
ggplot(AIC_AR, aes(x = Órden, y = AIC)) +
geom_line(color = "purple") +
geom_point(data = minAIC_AR, aes(x = Órden, y = AIC), size = 2, color = "magenta")
nottem_dif <- diff(nottem)
#q=
Acf(nottem_dif, lag.max = 200, type = "correlation", main = "")
options(width = 80) # mejora la visual de la salida
AIC_MA <- vector()
for (q in 1:200){
modelo <- arima(nottem, order = c(0,0,q))
AIC_MA[q] <- modelo$aic
}
Acf(nottem_dif, lag.max = 200, type = "correlation", main = "")
AIC_MA <- vector()
for (q in 1:200){
modelo <- arima(nottem, order = c(0,0,q))
AIC_MA[q] <- modelo$aic
}
nottem_dif <- diff(nottem)
#q=
Acf(nottem_dif, lag.max = 200, type = "correlation", main = "")
Acf(nottem_dif, lag.max = 60, type = "correlation", main = "")
options(width = 80) # mejora la visual de la salida
AIC_MA <- vector()
for (q in 1:60){
modelo <- arima(nottem, order = c(0,0,q))
AIC_MA[q] <- modelo$aic
}
nottem_dif <- diff(nottem)
#q=
Acf(nottem_dif, lag.max = 200, type = "correlation", main = "")
Acf(nottem_dif, lag.max = 40, type = "correlation", main = "")
options(width = 80) # mejora la visual de la salida
AIC_MA <- vector()
for (q in 1:40){
modelo <- arima(nottem, order = c(0,0,q))
AIC_MA[q] <- modelo$aic
}
AIC_MA
AIC_MA <- data.frame(Órden = 1:40, AIC = AIC_MA)
minAIC_MA <- filter(AIC_MA, AIC == min(AIC))
minAIC_MA
ggplot(AIC_MA, aes(x = Órden, y = AIC)) +
geom_line(color = "purple") +
geom_point(data = minAIC_MA, aes(x = Órden, y = AIC), size = 2, color = "magenta")
ARIMA <- arima(nottem_entrenamiento, order = c(25,0,37), method = "ML")
round(summary(ARIMA)$coef, 4)
autoARIMA_nodif <- auto.arima(nottem_entrenamiento)
autoARIMA <- auto.arima(nottem_entrenamiento)
#ver cual usar
summary(autoARIMA)
options(scipen = 999)
checkresiduals(ARIMA)
plotARIMA <- autoplot(predARIMA, xlab = "Tiempo", ylab = "Precios diferenciados", size = 1) +
theme_hc() +
theme(plot.title = element_text(size = 10, hjust = 0.5),
axis.title = element_text(size = 10),
axis.text = element_text(size = 10))
predARIMA <- forecast(ARIMA, h = 10)
options(width = 80) # mejora la visual de la salida
accuracy(predARIMA, nottem_prueba)
plotARIMA <- autoplot(predARIMA, xlab = "Tiempo", ylab = "Grados", size = 1) +
theme_hc() +
theme(plot.title = element_text(size = 10, hjust = 0.5),
axis.title = element_text(size = 10),
axis.text = element_text(size = 10))
plotARIMAzoom <- autoplot(nottem_prueba, xlab = "Tiempo", ylab = "Grados", size = 1) +
autolayer(predARIMA, alpha = .5) +
ggtitle("Predicciones vs. valores reales")  +
theme_hc() +
theme(plot.title = element_text(size = 10, hjust = 0.5),
axis.title = element_text(size = 10),
axis.text = element_text(size = 10))
grid.arrange(plotARIMA, plotARIMAzoom, ncol = 2)
Modelo <- c("ARIMA(25,1,50)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, autoARIMA$aic)
RMSE <- c(accuracy(predARIMA, nottem_prueba)[2,2],
accuracy(pred_autoARIMA, nottem_prueba)[2,2])
library(tidyverse)
library(rstudioapi)
setwd(dirname(getActiveDocumentContext()$path))
#getwd()
library(openxlsx)
medidas <- read.xlsx("MedidasCorporales.xlsx")
#str(medidas)
medidas<-na.omit(medidas)
view(medidas)
str(medidas)
attach(medidas)
# el documento posee 507 registros todos ellos completos en cada variable y existen 24 variables donde todas ellas son de tipo numérico
library(ggplot2)
library(ggpubr)
medidas1 <- data.frame(Altura, Peso)
cor(Peso,Altura)
reg_alturaPeso <- lm(formula = Peso ~ Altura,
data = medidas1)
residuos <- data.frame(Error = reg_alturaPeso$residuals)
reg_alturaPeso
#buscar modelo teorico
#b)
ggplot(data = medidas1, aes(x = Altura, y = Peso)) +
geom_point(col = "pink") +
geom_abline(slope = 1.017617, intercept = -105.011254, color = "purple") +
xlab("Peso") +
ylab("Altura (en cm)")
#c)
ggplot(data = residuos, aes(x = Error)) +
geom_histogram(fill = "pink", col = "purple") +
ylab("")
ggqqplot(data = residuos, x = "Error", color = "violet", pch = 16)
shapiro.test(residuos$Error)
reg_alturaPeso$coefficients
summary(reg_alturaPeso)
#Fijamos la semilla
set.seed(1234)
# Obtener el número total de registros
n <- nrow(medidas)
library(caret)
muestras<-1:dim(medidas)[1] %>%
createDataPartition(p = 0.8, list = FALSE)
entrenamiento <- medidas[muestras,]
prueba <- medidas[-muestras,]
# Realizar el modelo de regresión lineal múltiple
modelo <- lm(Peso ~ ., data = entrenamiento)
# Ver los resultados del modelo
summary(modelo)
# Revisar las variables significativas con un nivel de significancia del 5%
vars_significativas <- names(coef(modelo))[summary(modelo)$coefficients[,4] < 0.05]
vars_significativas
# Realizar el modelo de regresión lineal múltiple con las variables significativas
modelo_final <- lm(Peso ~ Profundidad.de.pecho + Diámetro.de.rodilla + Contorno.de.pecho+ Contorno.de.cintura + Contorno.de.cadera  + Contorno.de.muslo  + Contorno.de.antebrazo+ Contorno.de.rodilla + Contorno.de.pantorrilla + Edad + Altura, data = entrenamiento)
# Ver los resultados del modelo final
summary(modelo_final)
#Error cuadrático medio
options(width = 80) # (mejora visual de la salida)
predicciones1 <- predict(modelo, prueba, type = "response")
predicciones1
predicciones2<-predict(modelo_final, prueba, type = "response")
predicciones2
MSE1<-(1/100)*sum((prueba$Peso-predicciones1)^2)
MSE1
#5.630566
MSE2<-(1/100)*sum((prueba$Peso-predicciones2)^2)
MSE2
# 5.243309
detach()
Dolor <- read.xlsx("Dolor.xlsx")
Dolor_no_NA<- na.omit(Dolor)
library(tidyverse)
library(ggplot2)
library(ggthemes)
ggplot(data = Dolor, aes(x = Colesterol, y = Estrechamiento.arterias.coronarias)) +
geom_point(color = "pink") +
geom_smooth(method = "glm", method.args = list(family = "binomial"), color = "purple") +
xlab("Colesterol") +
ylab("Probabilidad de estrechamiento arterias coronarias") +
theme_hc()
log_simple_dolor <- glm(formula = Estrechamiento.arterias.coronarias~Colesterol,
data = Dolor_no_NA,
family='binomial')
summary(log_simple_dolor)
#escribir formula en word
nuevo_valor <- data.frame(Colesterol = c(199))
prob <- log_simple_dolor %>% predict(nuevo_valor, type = "response")
prob
#0.6193053
log_mult <- glm(formula = Estrechamiento.arterias.coronarias ~ Edad + Días.con.síntomas + Colesterol,
data = Dolor_no_NA,
family = "binomial")
summary(log_mult)
#edad y colesterol son significativas
Dolor_hombres <- Dolor[Dolor$Sexo == 0, ]
Dolor_mujeres<- Dolor[Dolor$Sexo == 1, ]
log_mult_homb <- glm(formula = Estrechamiento.arterias.coronarias ~ Edad + Días.con.síntomas + Colesterol,
data = Dolor_hombres,
family = "binomial")
summary(log_mult_homb)
#Edad, Colesterol
log_mult_muj <- glm(formula = Estrechamiento.arterias.coronarias ~ Edad + Días.con.síntomas + Colesterol,
data = Dolor_mujeres,
family = "binomial")
summary(log_mult_muj)
#Edad, Colesterol pero Días tiene mayor significancia pero apenas. esto marca que el sexo no es una gran diferencia
europa <- read.xlsx("Europa.xlsx")
#europa<-na.omit(europa)
options(width = 80) # (mejora visual de la salida)
glimpse(europa)
europa2 <- europa %>%
dplyr::select(-País)
Sigma = cov(europa2)
Sigma
det(Sigma)
autovalores <- eigen(Sigma)$values
autovalores
autovectores <- eigen(Sigma)$vectors
autovectores
library(corrplot)
options(width = 80) # (mejora visual de la salida)
PC <- prcomp(europa2, scale = TRUE)
correlaciones <- cor(PC$x, method = "pearson")
corrplot::corrplot(correlaciones, method = "color", tl.pos = "n")
library(rstudioapi)
library(tidyverse)
library(ggplot2)
library(fpp2)
library(ggthemes)
library(gridExtra)
library(tseries)
data(nottem)
head(nottem)
?nottem
#serie de tiempo
plot.ts(nottem, col ="royalblue", xlab = "Año", ylab = "Grados")
#aditiva
nottem_da <- decompose(nottem, type = "additive")
autoplot(nottem_da) +
geom_line(color = "violet") +
ggtitle("Descomposición aditiva") +
theme_hc() +
theme(plot.title = element_text(hjust = 0.5))
aditiva <- decompose(nottem, type = "additive")
#tendencia
plot.ts(aditiva$trend, col = "purple", xlab = "Año", ylab = "Grados",main='Tendencia')
varR <- var(na.omit(aditiva$random))
varTR <- var(na.omit(aditiva$trend) + na.omit(aditiva$random))
1 - varR / varTR #tendencia debil
#estacionalidad
plot.ts(aditiva$seasonal, col = "violet", xlab = "Año", ylab = "Grados", main='Estacionalidad')
varRe <- var(na.omit(aditiva$random))
varSR <- var(na.omit(aditiva$seasonal) + na.omit(aditiva$random))
1 - varRe / varSR
#multiplicativa
notem_dm <- decompose(nottem, type = "multiplicative")
autoplot(notem_dm) +
geom_line(color = "violet") +
ggtitle("Descomposición multiplicativa") +
theme_hc() +
theme(plot.title = element_text(hjust = 0.5))
multiplicativa <- decompose(nottem, type = "multiplicative")
plot.ts(multiplicativa$trend, col = "purple", xlab = "Año", ylab = "Grado", main = "Tendencia")
varRm <- var(na.omit(multiplicativa$random))
varTRm <- var(na.omit(multiplicativa$trend) * na.omit(multiplicativa$random))
1 - varRm / varTRm
plot.ts(multiplicativa$seasonal, col = "violet", xlab = "Año", ylab = "Grado", main="Estacionalidad")
varRem <- var(na.omit(multiplicativa$random))
varSRm <- var(na.omit(multiplicativa$seasonal) * na.omit(multiplicativa$random))
1 - varR / varSR
nottem_entrenamiento <- window(nottem, end = c(1938, 12))
nottem_prueba <- window(nottem, start = c(1939, 1))
lamb <- BoxCox.lambda(nottem)
lamb
nottemBC <- BoxCox(nottem, lambda = lamb)
sto <- autoplot(nottem, color = "royalblue", main =  "Serie de tiempo original", xlab = "", ylab = "") +
theme_hc() +
theme(plot.title = element_text(hjust = 0.5))
stt <- autoplot(nottemBC, color = "purple", main =  "Serie de tiempo transformada", xlab = "", ylab = "") +
theme_hc() +
theme(plot.title = element_text(hjust = 0.5))
grid.arrange(sto, stt, ncol = 1)
PP.test(nottem)
library(tseries)
kpss.test(nottem)
#calcular componentes:
#d=0 porque no se realizo diferenciacion
#p=
Acf(nottem, lag.max = 50, type = "partial", main = "")
#25
options(width = 80) # mejora la visual de la salida
AIC_AR <- vector()
for (p in 1:30){
modelo <- arima(nottem_entrenamiento, order = c(p,0,0))
AIC_AR[p] <- modelo$aic
}
options(scipen = 999)
checkresiduals(ARIMA)
pred_autoARIMA <- forecast(autoARIMA, h = 10)
options(width = 80) # mejora la visual de la salida
accuracy(pred_autoARIMA, nottem_prueba)
plot_autoARIMA <- autoplot(pred_autoARIMA, xlab = "Tiempo", ylab = "Precios diferenciados", size = 1) +
theme_hc() +
theme(plot.title = element_text(size = 10, hjust = 0.5),
axis.title = element_text(size = 10),
axis.text = element_text(size = 10))
plot_autoARIMAzoom <- autoplot(nottem_prueba, xlab = "Tiempo", ylab = "Precios diferenciados", size = 1) +
autolayer(pred_autoARIMA, alpha = .5) +
ggtitle("Predicciones vs. valores reales")  +
theme_hc() +
theme(plot.title = element_text(size = 10, hjust = 0.5),
axis.title = element_text(size = 10),
axis.text = element_text(size = 10))
grid.arrange(plot_autoARIMA, plot_autoARIMAzoom, ncol = 2)
checkresiduals(autoARIMA)
Modelo <- c("ARIMA(25,1,50)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, autoARIMA$aic)
RMSE <- c(accuracy(predARIMA, nottem_prueba)[2,2],
accuracy(pred_autoARIMA, nottem_prueba)[2,2])
MAPE <- c(
accuracy(predARIMA, nottem_prueba)[2,5],
accuracy(pred_autoARIMA, nottem_prueba)[2,5])
data.frame(Modelo = Modelo, AIC = AIC, RMSE = RMSE, MAPE = MAPE)
checkresiduals(autoARIMA)
Modelo <- c("ARIMA(25,1,50)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, autoARIMA$aic)
RMSE <- c(accuracy(predARIMA, nottem_prueba)[2,2],
accuracy(pred_autoARIMA, nottem_prueba)[2,2])
MAPE <- c(
accuracy(predARIMA, nottem_prueba)[2,5],
accuracy(pred_autoARIMA, nottem_prueba)[2,5])
data.frame(Modelo = Modelo, AIC = AIC, RMSE = RMSE, MAPE = MAPE)
Modelo <- c("ARIMA(25,1,37)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, autoARIMA$aic)
RMSE <- c(accuracy(predARIMA, nottem_prueba)[2,2],
accuracy(pred_autoARIMA, nottem_prueba)[2,2])
MAPE <- c(
accuracy(predARIMA, nottem_prueba)[2,5],
accuracy(pred_autoARIMA, nottem_prueba)[2,5])
data.frame(Modelo = Modelo, AIC = AIC, RMSE = RMSE, MAPE = MAPE)
Modelo <- c("ARIMA(25,1,37)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, $autoARIMA$aic)
Modelo <- c("ARIMA(25,1,37)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, autoARIMA$aic)
RMSE <- c(accuracy(predARIMA, nottem_prueba)[2,2],
accuracy(pred_autoARIMA, nottem_prueba)[2,2])
MAPE <- c(
accuracy(predARIMA, nottem_prueba)[2,5],
accuracy(pred_autoARIMA, nottem_prueba)[2,5])
data.frame(Modelo = Modelo, AIC = AIC, RMSE = RMSE, MAPE = MAPE)
Modelo <- c("ARIMA(25,1,37)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, autoARIMA$aic)
RMSE <- c(accuracy(predARIMA, nottem_prueba)[2,2],
accuracy(pred_autoARIMA, nottem_prueba)[2,2])
MAPE <- c(
accuracy(predARIMA, nottem_prueba)[2,5],
accuracy(pred_autoARIMA, nottem_prueba)[2,5])
data.frame(Modelo = Modelo, AIC = AIC, RMSE = RMSE, MAPE = MAPE)
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon') )
install.packages(c("repr", "IRdisplay", "evaluate", "crayon"))
install.packages(c('pbdZMQ', 'devtools', 'uuid', 'digest') )
install.packages('IRkernel')
library( "IRkernel" ) IRkernel::installspec()
library( "IRkernel" )
library( "IRkernel" ) IRkernel::installspec()
IRkernel::installspec()
library( "IRkernel" ) IRkernel::installspec()
library( "IRkernel" )
IRkernel::installspec()
IRkernel::installspec()
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon') ) install.packages(c('pbdZMQ', 'devtools', 'uuid', 'digest') ) install.packages('IRkernel')
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon') )
install.packages(c('pbdZMQ', 'devtools', 'uuid', 'digest') )
install.packages('IRkernel')
library( "IRkernel" )
IRkernel::installspec()
quit()
#Ensemble de arboles de decision
#utilizando el naif metodo de Arboles Azarosos
#entreno cada arbol utilizando un subconjunto distinto de atributos del dataset
#Para detener el script y mostrar el stack ante un error
options(error = function() {
traceback(20);
options(error = NULL);
stop("\nAbortando luego de un error fatal en el script.\n")
})
#limpio la memoria
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
# INICIO parametros experimento
PARAM <- list()
PARAM$experimento  <- 3212
PARAM$semilla  <- 999959      #Establezco la semilla aleatoria, cambiar por SU primer semilla
#parameetros rpart
PARAM$rpart_param   <- list( "cp"=          -1,
"minsplit"=  100,
"minbucket"=  10,
"maxdepth"=   14 )
#parametros  arbol
PARAM$feature_fraction  <- 0.5  #entreno cada arbol con solo 50% de las variables variables
PARAM$num_trees_max  <- 500 #voy a generar 500 arboles, a mas arboles mas tiempo de proceso y MEJOR MODELO, pero ganancias marginales
# FIN parametros experimento
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
#Aqui comienza el programa
setwd("C:/Users/varon/OneDrive/Escritorio/Data_mining")  #Establezco el Working Directory
#cargo los datos
dataset  <- fread("./datasets/dataset_pequeno.csv")
#creo la carpeta donde va el experimento
dir.create( "./exp/", showWarnings = FALSE  )
carpeta_experimento  <-  paste0( "./exp/KA", PARAM$experimento, "/")
dir.create( paste0( "./exp/KA", PARAM$experimento, "/"),
showWarnings = FALSE )
setwd( carpeta_experimento )
#que tamanos de ensemble grabo a disco, pero siempre debo generar los 500
grabar  <- c( 1, 5, 10, 50, 100, 200, 500)
#defino los dataset de entrenamiento y aplicacion
dtrain  <- dataset[ foto_mes==202107 ]
dapply  <- dataset[ foto_mes==202109 ]
#aqui se va acumulando la probabilidad del ensemble
dapply[ , prob_acumulada := 0 ]
#Establezco cuales son los campos que puedo usar para la prediccion
#el copy() es por la Lazy Evaluation
campos_buenos  <- copy( setdiff(  colnames(dtrain) ,  c("clase_ternaria") ) )
#Genero las salidas
set.seed(PARAM$semilla) #Establezco la semilla aleatoria
for( arbolito in  1:PARAM$num_trees_max )
{
qty_campos_a_utilizar  <- as.integer( length(campos_buenos)* PARAM$feature_fraction )
campos_random  <- sample( campos_buenos, qty_campos_a_utilizar )
#paso de un vector a un string con los elementos separados por un signo de "+"
#este hace falta para la formula
campos_random  <- paste( campos_random, collapse=" + ")
#armo la formula para rpart
formulita  <- paste0( "clase_ternaria ~ ", campos_random )
#genero el arbol de decision
modelo  <- rpart( formulita,
data= dtrain,
xval= 0,
control= PARAM$rpart_param )
#aplico el modelo a los datos que no tienen clase
prediccion  <- predict( modelo, dapply , type = "prob")
dapply[  ,  prob_acumulada :=  prob_acumulada + prediccion[ , "BAJA+2"] ]
if( arbolito %in%  grabar )
{
#Genero la entrega para Kaggle
umbral_corte  <-  (1/40) *  arbolito
entrega  <- as.data.table( list( "numero_de_cliente"= dapply[  , numero_de_cliente],
"Predicted"= as.numeric(dapply[  , prob_acumulada] > umbral_corte) ) ) #genero la salida
nom_arch  <- paste0('KA', PARAM$experimento, "_",
sprintf( '%.3d', arbolito ), #para que tenga ceros adelante
'.csv' )
fwrite( entrega,
file= nom_arch,
sep= "," )
cat( arbolito, " " )
}
cat( arbolito, "\n" )  #imprimo cada pasada para no angustiarme
}
