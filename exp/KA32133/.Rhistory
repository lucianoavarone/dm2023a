varTR <- var(na.omit(aditiva$trend) + na.omit(aditiva$random))
1 - varR / varTR #tendencia debil
#estacionalidad
plot.ts(aditiva$seasonal, col = "violet", xlab = "Año", ylab = "Grados", main='Estacionalidad')
varRe <- var(na.omit(aditiva$random))
varSR <- var(na.omit(aditiva$seasonal) + na.omit(aditiva$random))
1 - varRe / varSR
#multiplicativa
notem_dm <- decompose(nottem, type = "multiplicative")
autoplot(notem_dm) +
geom_line(color = "violet") +
ggtitle("Descomposición multiplicativa") +
theme_hc() +
theme(plot.title = element_text(hjust = 0.5))
multiplicativa <- decompose(nottem, type = "multiplicative")
plot.ts(multiplicativa$trend, col = "purple", xlab = "Año", ylab = "Grado", main = "Tendencia")
varRm <- var(na.omit(multiplicativa$random))
varTRm <- var(na.omit(multiplicativa$trend) * na.omit(multiplicativa$random))
1 - varRm / varTRm
plot.ts(multiplicativa$seasonal, col = "violet", xlab = "Año", ylab = "Grado", main="Estacionalidad")
varRem <- var(na.omit(multiplicativa$random))
varSRm <- var(na.omit(multiplicativa$seasonal) * na.omit(multiplicativa$random))
1 - varR / varSR
nottem_entrenamiento <- window(nottem, end = c(1938, 12))
nottem_prueba <- window(nottem, start = c(1939, 1))
lamb <- BoxCox.lambda(nottem)
lamb
nottemBC <- BoxCox(nottem, lambda = lamb)
sto <- autoplot(nottem, color = "royalblue", main =  "Serie de tiempo original", xlab = "", ylab = "") +
theme_hc() +
theme(plot.title = element_text(hjust = 0.5))
stt <- autoplot(nottemBC, color = "purple", main =  "Serie de tiempo transformada", xlab = "", ylab = "") +
theme_hc() +
theme(plot.title = element_text(hjust = 0.5))
grid.arrange(sto, stt, ncol = 1)
PP.test(nottem)
library(tseries)
kpss.test(nottem)
#calcular componentes:
#d=0 porque no se realizo diferenciacion
#p=
Acf(nottem, lag.max = 50, type = "partial", main = "")
#25
options(width = 80) # mejora la visual de la salida
AIC_AR <- vector()
for (p in 1:30){
modelo <- arima(nottem_entrenamiento, order = c(p,0,0))
AIC_AR[p] <- modelo$aic
}
options(scipen = 999)
checkresiduals(ARIMA)
pred_autoARIMA <- forecast(autoARIMA, h = 10)
options(width = 80) # mejora la visual de la salida
accuracy(pred_autoARIMA, nottem_prueba)
plot_autoARIMA <- autoplot(pred_autoARIMA, xlab = "Tiempo", ylab = "Precios diferenciados", size = 1) +
theme_hc() +
theme(plot.title = element_text(size = 10, hjust = 0.5),
axis.title = element_text(size = 10),
axis.text = element_text(size = 10))
plot_autoARIMAzoom <- autoplot(nottem_prueba, xlab = "Tiempo", ylab = "Precios diferenciados", size = 1) +
autolayer(pred_autoARIMA, alpha = .5) +
ggtitle("Predicciones vs. valores reales")  +
theme_hc() +
theme(plot.title = element_text(size = 10, hjust = 0.5),
axis.title = element_text(size = 10),
axis.text = element_text(size = 10))
grid.arrange(plot_autoARIMA, plot_autoARIMAzoom, ncol = 2)
checkresiduals(autoARIMA)
Modelo <- c("ARIMA(25,1,50)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, autoARIMA$aic)
RMSE <- c(accuracy(predARIMA, nottem_prueba)[2,2],
accuracy(pred_autoARIMA, nottem_prueba)[2,2])
MAPE <- c(
accuracy(predARIMA, nottem_prueba)[2,5],
accuracy(pred_autoARIMA, nottem_prueba)[2,5])
data.frame(Modelo = Modelo, AIC = AIC, RMSE = RMSE, MAPE = MAPE)
checkresiduals(autoARIMA)
Modelo <- c("ARIMA(25,1,50)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, autoARIMA$aic)
RMSE <- c(accuracy(predARIMA, nottem_prueba)[2,2],
accuracy(pred_autoARIMA, nottem_prueba)[2,2])
MAPE <- c(
accuracy(predARIMA, nottem_prueba)[2,5],
accuracy(pred_autoARIMA, nottem_prueba)[2,5])
data.frame(Modelo = Modelo, AIC = AIC, RMSE = RMSE, MAPE = MAPE)
Modelo <- c("ARIMA(25,1,37)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, autoARIMA$aic)
RMSE <- c(accuracy(predARIMA, nottem_prueba)[2,2],
accuracy(pred_autoARIMA, nottem_prueba)[2,2])
MAPE <- c(
accuracy(predARIMA, nottem_prueba)[2,5],
accuracy(pred_autoARIMA, nottem_prueba)[2,5])
data.frame(Modelo = Modelo, AIC = AIC, RMSE = RMSE, MAPE = MAPE)
Modelo <- c("ARIMA(25,1,37)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, $autoARIMA$aic)
Modelo <- c("ARIMA(25,1,37)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, autoARIMA$aic)
RMSE <- c(accuracy(predARIMA, nottem_prueba)[2,2],
accuracy(pred_autoARIMA, nottem_prueba)[2,2])
MAPE <- c(
accuracy(predARIMA, nottem_prueba)[2,5],
accuracy(pred_autoARIMA, nottem_prueba)[2,5])
data.frame(Modelo = Modelo, AIC = AIC, RMSE = RMSE, MAPE = MAPE)
Modelo <- c("ARIMA(25,1,37)", "AutoARIMA")
AIC <- c(summary(ses_opt)$ARIMA$aic, autoARIMA$aic)
RMSE <- c(accuracy(predARIMA, nottem_prueba)[2,2],
accuracy(pred_autoARIMA, nottem_prueba)[2,2])
MAPE <- c(
accuracy(predARIMA, nottem_prueba)[2,5],
accuracy(pred_autoARIMA, nottem_prueba)[2,5])
data.frame(Modelo = Modelo, AIC = AIC, RMSE = RMSE, MAPE = MAPE)
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon') )
install.packages(c("repr", "IRdisplay", "evaluate", "crayon"))
install.packages(c('pbdZMQ', 'devtools', 'uuid', 'digest') )
install.packages('IRkernel')
library( "IRkernel" ) IRkernel::installspec()
library( "IRkernel" )
library( "IRkernel" ) IRkernel::installspec()
IRkernel::installspec()
library( "IRkernel" ) IRkernel::installspec()
library( "IRkernel" )
IRkernel::installspec()
IRkernel::installspec()
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon') ) install.packages(c('pbdZMQ', 'devtools', 'uuid', 'digest') ) install.packages('IRkernel')
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon') )
install.packages(c('pbdZMQ', 'devtools', 'uuid', 'digest') )
install.packages('IRkernel')
library( "IRkernel" )
IRkernel::installspec()
quit()
pacman::p_load(rvest,dplyr,xml2,tidyverse,RCurl,XML,readxl,splitstackshape,writexl)
# Function to extract text from long articles
extract_body_text <- function(text) {
if (nchar(text, type = "chars", allowNA = FALSE, keepNA = NA) > 32000) {
sentences <- unlist(strsplit(text, "।", perl = TRUE))
num_sentences <- length(sentences)
if (num_sentences < 2) {
sentences <- unlist(strsplit(text, ".", perl = TRUE))
num_sentences <- length(sentences)
}
body_text <- ""
for (n in 1:num_sentences) {
txt_sent <- sentences[n]
body_text <- txt_sent
body_text <- str_c(body_text, collapse = "")
}
} else {
body_text <- text
}
return(body_text)
}
list_of_files <- list.files(path = "C:/Users/varon/OneDrive/Escritorio/investigacion/bases de datos/Arabia_Saudita", recursive = TRUE,
pattern = "\\.csv$",
full.names = FALSE)
links <- character()
for (i in 1:length(list_of_files)){
txt1 <- paste("ua_temp <-read.csv('C:/Users/varon/OneDrive/Escritorio/investigacion/bases de datos/Arabia_Saudita/", list_of_files[i],"')",sep="")
eval(parse(text=txt1))
ua_temp <- ua_temp[,1]
if (i==1){
links <- ua_temp
} else {
links <- c(links,ua_temp)
}
print(paste("File", i, "processed."))
}
links <- links[grepl("https://www.mofa.gov.sa/", links, fixed = TRUE)]
links <- links[!grepl("https://www.mofa.gov.sa/aboutKingDom/", links, fixed = TRUE)]
links <- links[!grepl("https://www.mofa.gov.sa/aboutMinistry", links, fixed = TRUE)]
links <- links[!grepl("https://www.mofa.gov.sa/ar/ministry/Pages/", links, fixed = TRUE)]
links <- sort(links)
links<-unique(links)
# Base mistakes
Arabia_Saudita <- data.frame(url = links, title = NA, date = NA, text = NA, stringsAsFactors = FALSE)
Arabia_Saudita.Mistakes <- data.frame(url = character(),
stringsAsFactors = FALSE)
# Unique
Arabia_Saudita<- unique(Arabia_Saudita)
for (i in seq_len(nrow(Arabia_Saudita))) {
url <- Arabia_Saudita$url[i]
tryCatch({
html <- read_html(url)
title <- html_text(html_node(html, "#pageTitle"))
date <- html_text(html_node(html, ".date-line")) #
#date <- date[endsWith(date,'. m.') | endsWith(date,'.m.')]
# date<- gsub("-.*","",date)
text <- html_text(html_node(html, ".page-content"))
date <- str_squish(date)
title <- str_squish(title)
text <- str_squish(text)
body_text <- extract_body_text(text)
Arabia_Saudita$title[i] <- title
Arabia_Saudita$date[i] <- date
Arabia_Saudita$text[i] <- body_text
cat(paste0("Link ", i, " of ", nrow(Arabia_Saudita), " processed successfully.\n"))
}, error = function(e) {
cat(paste0("Link ", i, " of ", nrow(Arabia_Saudita), " failed with error: ", e$message, "\n"))
Arabia_Saudita.Mistakes <<- rbind(Arabia_Saudita.Mistakes, data.frame(url = url), stringsAsFactors = FALSE)
})
}
View(Arabia_Saudita)
pacman::p_load(rvest,dplyr,xml2,tidyverse,RCurl,XML,readxl,splitstackshape,writexl)
# Function to extract text from long articles
extract_body_text <- function(text) {
if (nchar(text, type = "chars", allowNA = FALSE, keepNA = NA) > 32000) {
sentences <- unlist(strsplit(text, "।", perl = TRUE))
num_sentences <- length(sentences)
if (num_sentences < 2) {
sentences <- unlist(strsplit(text, ".", perl = TRUE))
num_sentences <- length(sentences)
}
body_text <- ""
for (n in 1:num_sentences) {
txt_sent <- sentences[n]
body_text <- txt_sent
body_text <- str_c(body_text, collapse = "")
}
} else {
body_text <- text
}
return(body_text)
}
list_of_files <- list.files(path = "C:/Users/varon/OneDrive/Escritorio/investigacion/bases de datos/Arabia_Saudita", recursive = TRUE,
pattern = "\\.csv$",
full.names = FALSE)
links <- character()
for (i in 1:length(list_of_files)){
txt1 <- paste("ua_temp <-read.csv('C:/Users/varon/OneDrive/Escritorio/investigacion/bases de datos/Arabia_Saudita/", list_of_files[i],"')",sep="")
eval(parse(text=txt1))
ua_temp <- ua_temp[,1]
if (i==1){
links <- ua_temp
} else {
links <- c(links,ua_temp)
}
print(paste("File", i, "processed."))
}
links <- links[grepl("https://www.mofa.gov.sa/", links, fixed = TRUE)]
links <- links[!grepl("https://www.mofa.gov.sa/aboutKingDom/", links, fixed = TRUE)]
links <- links[!grepl("https://www.mofa.gov.sa/aboutMinistry", links, fixed = TRUE)]
links <- links[!grepl("https://www.mofa.gov.sa/ar/ministry/Pages/", links, fixed = TRUE)]
links <- sort(links)
links<-unique(links)
# Base mistakes
Arabia_Saudita <- data.frame(url = links, title = NA, date = NA, text = NA, stringsAsFactors = FALSE)
Arabia_Saudita.Mistakes <- data.frame(url = character(),
stringsAsFactors = FALSE)
# Unique
Arabia_Saudita<- unique(Arabia_Saudita)
for (i in seq_len(nrow(Arabia_Saudita))) {
url <- Arabia_Saudita$url[i]
tryCatch({
html <- read_html(url)
title <- html_text(html_node(html, "#DeltaPlaceHolderPageTitleInTitleArea"))
date <- html_text(html_node(html, ".date-line")) #
#date <- date[endsWith(date,'. m.') | endsWith(date,'.m.')]
# date<- gsub("-.*","",date)
text <- html_text(html_node(html, ".page-content"))
date <- str_squish(date)
title <- str_squish(title)
text <- str_squish(text)
body_text <- extract_body_text(text)
Arabia_Saudita$title[i] <- title
Arabia_Saudita$date[i] <- date
Arabia_Saudita$text[i] <- body_text
cat(paste0("Link ", i, " of ", nrow(Arabia_Saudita), " processed successfully.\n"))
}, error = function(e) {
cat(paste0("Link ", i, " of ", nrow(Arabia_Saudita), " failed with error: ", e$message, "\n"))
Arabia_Saudita.Mistakes <<- rbind(Arabia_Saudita.Mistakes, data.frame(url = url), stringsAsFactors = FALSE)
})
}
View(Arabia_Saudita)
pacman::p_load(rvest,dplyr,xml2,tidyverse,RCurl,XML,readxl,splitstackshape,writexl)
# Function to extract text from long articles
extract_body_text <- function(text) {
if (nchar(text, type = "chars", allowNA = FALSE, keepNA = NA) > 32000) {
sentences <- unlist(strsplit(text, "।", perl = TRUE))
num_sentences <- length(sentences)
if (num_sentences < 2) {
sentences <- unlist(strsplit(text, ".", perl = TRUE))
num_sentences <- length(sentences)
}
body_text <- ""
for (n in 1:num_sentences) {
txt_sent <- sentences[n]
body_text <- txt_sent
body_text <- str_c(body_text, collapse = "")
}
} else {
body_text <- text
}
return(body_text)
}
list_of_files <- list.files(path = "C:/Users/varon/OneDrive/Escritorio/investigacion/bases de datos/Arabia_Saudita", recursive = TRUE,
pattern = "\\.csv$",
full.names = FALSE)
links <- character()
for (i in 1:length(list_of_files)){
txt1 <- paste("ua_temp <-read.csv('C:/Users/varon/OneDrive/Escritorio/investigacion/bases de datos/Arabia_Saudita/", list_of_files[i],"')",sep="")
eval(parse(text=txt1))
ua_temp <- ua_temp[,1]
if (i==1){
links <- ua_temp
} else {
links <- c(links,ua_temp)
}
print(paste("File", i, "processed."))
}
links <- links[grepl("https://www.mofa.gov.sa/", links, fixed = TRUE)]
links <- links[!grepl("https://www.mofa.gov.sa/aboutKingDom/", links, fixed = TRUE)]
links <- links[!grepl("https://www.mofa.gov.sa/aboutMinistry", links, fixed = TRUE)]
links <- links[!grepl("https://www.mofa.gov.sa/ar/ministry/Pages/", links, fixed = TRUE)]
links <- links[grepl("https://www.mofa.gov.sa/en/ministry/news/", links, fixed = TRUE)]
links <- sort(links)
links<-unique(links)
# Base mistakes
Arabia_Saudita <- data.frame(url = links, title = NA, date = NA, text = NA, stringsAsFactors = FALSE)
Arabia_Saudita.Mistakes <- data.frame(url = character(),
stringsAsFactors = FALSE)
# Unique
Arabia_Saudita<- unique(Arabia_Saudita)
for (i in seq_len(nrow(Arabia_Saudita))) {
url <- Arabia_Saudita$url[i]
tryCatch({
html <- read_html(url)
title <- html_text(html_node(html, "#DeltaPlaceHolderPageTitleInTitleArea"))
date <- html_text(html_node(html, ".date-line")) #
#date <- date[endsWith(date,'. m.') | endsWith(date,'.m.')]
# date<- gsub("-.*","",date)
text <- html_text(html_node(html, ".page-content"))
date <- str_squish(date)
title <- str_squish(title)
text <- str_squish(text)
body_text <- extract_body_text(text)
Arabia_Saudita$title[i] <- title
Arabia_Saudita$date[i] <- date
Arabia_Saudita$text[i] <- body_text
cat(paste0("Link ", i, " of ", nrow(Arabia_Saudita), " processed successfully.\n"))
}, error = function(e) {
cat(paste0("Link ", i, " of ", nrow(Arabia_Saudita), " failed with error: ", e$message, "\n"))
Arabia_Saudita.Mistakes <<- rbind(Arabia_Saudita.Mistakes, data.frame(url = url), stringsAsFactors = FALSE)
})
}
View(Arabia_Saudita)
#Ensemble de arboles de decision
#utilizando el naif metodo de Arboles Azarosos
#entreno cada arbol utilizando un subconjunto distinto de atributos del dataset
#Para detener el script y mostrar el stack ante un error
options(error = function() {
traceback(20);
options(error = NULL);
stop("\nAbortando luego de un error fatal en el script.\n")
})
#limpio la memoria
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
# INICIO parametros experimento
PARAM <- list()
PARAM$experimento  <- 3213
PARAM$semilla  <- 999959      #Establezco la semilla aleatoria, cambiar por SU primer semilla
#parameetros rpart
PARAM$rpart_param   <- list( "cp"=          -1,
"minsplit"=  250,
"minbucket"=  50,
"maxdepth"=   6 )
#parametros  arbol
PARAM$feature_fraction  <- 0.5  #entreno cada arbol con solo 50% de las variables variables
PARAM$num_trees_max  <- 500 #voy a generar 500 arboles, a mas arboles mas tiempo de proceso y MEJOR MODELO, pero ganancias marginales
# FIN parametros experimento
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
#Aqui comienza el programa
setwd("C:/Users/varon/OneDrive/Escritorio/Data_mining")  #Establezco el Working Directory
#cargo los datos
dataset  <- fread("./datasets/dataset_pequeno.csv")
#creo la carpeta donde va el experimento
dir.create( "./exp/", showWarnings = FALSE  )
carpeta_experimento  <-  paste0( "./exp/KA", PARAM$experimento, "/")
dir.create( paste0( "./exp/KA", PARAM$experimento, "/"),
showWarnings = FALSE )
setwd( carpeta_experimento )
#que tamanos de ensemble grabo a disco, pero siempre debo generar los 500
grabar  <- c( 1, 5, 10, 50, 100, 200, 500)
#defino los dataset de entrenamiento y aplicacion
dtrain  <- dataset[ foto_mes==202107 ]
dapply  <- dataset[ foto_mes==202109 ]
#aqui se va acumulando la probabilidad del ensemble
dapply[ , prob_acumulada := 0 ]
#Establezco cuales son los campos que puedo usar para la prediccion
#el copy() es por la Lazy Evaluation
campos_buenos  <- copy( setdiff(  colnames(dtrain) ,  c("clase_ternaria") ) )
#Genero las salidas
set.seed(PARAM$semilla) #Establezco la semilla aleatoria
for( arbolito in  1:PARAM$num_trees_max )
{
qty_campos_a_utilizar  <- as.integer( length(campos_buenos)* PARAM$feature_fraction )
campos_random  <- sample( campos_buenos, qty_campos_a_utilizar )
#paso de un vector a un string con los elementos separados por un signo de "+"
#este hace falta para la formula
campos_random  <- paste( campos_random, collapse=" + ")
#armo la formula para rpart
formulita  <- paste0( "clase_ternaria ~ ", campos_random )
#genero el arbol de decision
modelo  <- rpart( formulita,
data= dtrain,
xval= 0,
control= PARAM$rpart_param )
#aplico el modelo a los datos que no tienen clase
prediccion  <- predict( modelo, dapply , type = "prob")
dapply[  ,  prob_acumulada :=  prob_acumulada + prediccion[ , "BAJA+2"] ]
if( arbolito %in%  grabar )
{
#Genero la entrega para Kaggle
umbral_corte  <-  (1/40) *  arbolito
entrega  <- as.data.table( list( "numero_de_cliente"= dapply[  , numero_de_cliente],
"Predicted"= as.numeric(dapply[  , prob_acumulada] > umbral_corte) ) ) #genero la salida
nom_arch  <- paste0('KA', PARAM$experimento, "_",
sprintf( '%.3d', arbolito ), #para que tenga ceros adelante
'.csv' )
fwrite( entrega,
file= nom_arch,
sep= "," )
cat( arbolito, " " )
}
cat( arbolito, "\n" )  #imprimo cada pasada para no angustiarme
}
#Ensemble de arboles de decision
#utilizando el naif metodo de Arboles Azarosos
#entreno cada arbol utilizando un subconjunto distinto de atributos del dataset
#Para detener el script y mostrar el stack ante un error
options(error = function() {
traceback(20);
options(error = NULL);
stop("\nAbortando luego de un error fatal en el script.\n")
})
#limpio la memoria
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
# INICIO parametros experimento
PARAM <- list()
PARAM$experimento  <- 32133
PARAM$semilla  <- 999959      #Establezco la semilla aleatoria, cambiar por SU primer semilla
#parameetros rpart
PARAM$rpart_param   <- list( "cp"=          -1,
"minsplit"=  250,
"minbucket"=  50,
"maxdepth"=   6 )
#parametros  arbol
PARAM$feature_fraction  <- 0.5  #entreno cada arbol con solo 50% de las variables variables
PARAM$num_trees_max  <- 500 #voy a generar 500 arboles, a mas arboles mas tiempo de proceso y MEJOR MODELO, pero ganancias marginales
# FIN parametros experimento
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
#Aqui comienza el programa
setwd("C:/Users/varon/OneDrive/Escritorio/Data_mining")  #Establezco el Working Directory
#cargo los datos
dataset  <- fread("./datasets/dataset_pequeno.csv")
#creo la carpeta donde va el experimento
dir.create( "./exp/", showWarnings = FALSE  )
carpeta_experimento  <-  paste0( "./exp/KA", PARAM$experimento, "/")
dir.create( paste0( "./exp/KA", PARAM$experimento, "/"),
showWarnings = FALSE )
setwd( carpeta_experimento )
#que tamanos de ensemble grabo a disco, pero siempre debo generar los 500
grabar  <- c( 1, 5, 10, 50, 100, 200, 500)
#defino los dataset de entrenamiento y aplicacion
dtrain  <- dataset[ foto_mes==202107 ]
dapply  <- dataset[ foto_mes==202109 ]
#aqui se va acumulando la probabilidad del ensemble
dapply[ , prob_acumulada := 0 ]
#Establezco cuales son los campos que puedo usar para la prediccion
#el copy() es por la Lazy Evaluation
campos_buenos  <- copy( setdiff(  colnames(dtrain) ,  c("clase_ternaria") ) )
#Genero las salidas
set.seed(PARAM$semilla) #Establezco la semilla aleatoria
for( arbolito in  1:PARAM$num_trees_max )
{
qty_campos_a_utilizar  <- as.integer( length(campos_buenos)* PARAM$feature_fraction )
campos_random  <- sample( campos_buenos, qty_campos_a_utilizar )
#paso de un vector a un string con los elementos separados por un signo de "+"
#este hace falta para la formula
campos_random  <- paste( campos_random, collapse=" + ")
#armo la formula para rpart
formulita  <- paste0( "clase_ternaria ~ ", campos_random )
#genero el arbol de decision
modelo  <- rpart( formulita,
data= dtrain,
xval= 0,
control= PARAM$rpart_param )
#aplico el modelo a los datos que no tienen clase
prediccion  <- predict( modelo, dapply , type = "prob")
dapply[  ,  prob_acumulada :=  prob_acumulada + prediccion[ , "BAJA+2"] ]
if( arbolito %in%  grabar )
{
#Genero la entrega para Kaggle
umbral_corte  <-  (1/40) *  arbolito
entrega  <- as.data.table( list( "numero_de_cliente"= dapply[  , numero_de_cliente],
"Predicted"= as.numeric(dapply[  , prob_acumulada] > umbral_corte) ) ) #genero la salida
nom_arch  <- paste0('KA', PARAM$experimento, "_",
sprintf( '%.3d', arbolito ), #para que tenga ceros adelante
'.csv' )
fwrite( entrega,
file= nom_arch,
sep= "," )
cat( arbolito, " " )
}
cat( arbolito, "\n" )  #imprimo cada pasada para no angustiarme
}
